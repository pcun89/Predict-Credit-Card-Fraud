import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

def loadAndPreprocessData(filePath):
    df = pd.read_csv(filePath)
    print("Initial class distribution:\n", df['Class'].value_counts())

    X = df.drop('Class', axis=1)
    y = df['Class']

    # Standardize 'Amount' and 'Time' columns
    X['Amount'] = StandardScaler().fit_transform(X['Amount'].values.reshape(-1, 1))
    X['Time'] = StandardScaler().fit_transform(X['Time'].values.reshape(-1, 1))

    return X, y


def balanceDataset(X, y):
    smote = SMOTE(random_state=42)
    X_resampled, y_resampled = smote.fit_resample(X, y)
    print("Resampled class distribution:\n",
          pd.Series(y_resampled).value_counts())
    return X_resampled, y_resampled


def trainAndEvaluateModel(X_train, X_test, y_train, y_test):
    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000),
        'Random Forest': RandomForestClassifier()
    }

    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        print(f"\n{name} Evaluation:")
        print(confusion_matrix(y_test, y_pred))
        print(classification_report(y_test, y_pred, digits=4))


def tuneHyperparameters(X_train, y_train):
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5]
    }
    grid = GridSearchCV(RandomForestClassifier(), param_grid,
                        cv=3, scoring='f1', n_jobs=-1)
    grid.fit(X_train, y_train)
    print("\nBest Random Forest Params:", grid.best_params_)
    return grid.best_estimator_
